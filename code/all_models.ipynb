{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26c8c700-69eb-476f-bc9d-27b0844d4ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV, cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (confusion_matrix, ConfusionMatrixDisplay,\n",
    "    accuracy_score, roc_auc_score, recall_score, precision_score, f1_score, RocCurveDisplay)\n",
    "from imblearn.metrics import specificity_score\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.ensemble import StackingClassifier, RandomForestClassifier, GradientBoostingClassifier, BaggingClassifier, AdaBoostClassifier\n",
    "\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "981011e9-558a-4aea-a2b4-981e641e43ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>using electric water boiler to mine bitcoin th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>btc to usdt hello i am looking to swap a good ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subreddit                                               text\n",
       "0          0  using electric water boiler to mine bitcoin th...\n",
       "1          0  btc to usdt hello i am looking to swap a good ..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_selftext = pd.read_csv('../data/cleaned_selftext.csv')\n",
    "df_notext = pd.read_csv('../data/cleaned_notext.csv')\n",
    "df_selftext.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ab056b0-14e2-4203-9d9a-d0043cc0dc99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    4017\n",
      "1     787\n",
      "Name: subreddit, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    9938\n",
       "1    2059\n",
       "Name: subreddit, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df_selftext.subreddit.value_counts())\n",
    "df_notext.subreddit.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd1b1d92-3bda-436a-b72d-d793579a6ae6",
   "metadata": {},
   "source": [
    "# Adding stop words to not make it too easy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "61d99e0f-41dd-481e-944c-9e2463e4e429",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop = list(stopwords.words('english'))\n",
    "stop.extend('btc eth bitcoin ethereum lightning vitalik metamask nft nfts'.split())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70425197-13d2-4f74-8094-de3e451564fe",
   "metadata": {},
   "source": [
    "# TTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8552c791-8e62-481f-a684-7287bcde817a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_selftext.text\n",
    "y = df_selftext.subreddit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a70c302-0e55-4339-8d17-af0b2959cada",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.836178\n",
       "1    0.163822\n",
       "Name: subreddit, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# baseline\n",
    "y.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "55061841-2e4b-4118-bd78-f0cbdf322687",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    stratify=y,\n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6896253a-348f-4f08-b3aa-8d0074533a02",
   "metadata": {},
   "source": [
    "# Model 1: NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ee29da9c-880d-4b49-8d59-c9e6feee1e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline accepts multiple transformers, but only one vectorizer. See cgpt results:\n",
    "\n",
    "'''The error message is caused by the fact that you are trying to fit two different vectorizers (TfidfVectorizer and CountVectorizer) \n",
    "in the same pipeline, but only providing one input (X_train) to the pipeline. This is causing the pipeline to raise an error as it doesn't \n",
    "know which vectorizer to apply to the input. \n",
    "\n",
    "You can fix this by either removing one of the vectorizers or providing separate inputs to the pipeline for each vectorizer.'''\n",
    "\n",
    "\n",
    "nb_pipe = Pipeline([\n",
    "    ('tvec', TfidfVectorizer()),\n",
    "    ('nb', MultinomialNB())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d3f71c4c-3fe4-40e6-93a7-10a3ba650c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_pipe_params = {\n",
    "    'tvec__max_features': range(600,800,5),\n",
    "    'tvec__stop_words': [stop],\n",
    "    'tvec__ngram_range': [(1,1), (1,2), (1,3),(2,3),(3,3)],\n",
    "    'nb__alpha': [.01, .05, .1, .25, .5, .1]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "91d2879f-9997-4d7d-a96a-0e05a85d24eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_rs = RandomizedSearchCV(nb_pipe, \n",
    "                  nb_pipe_params, \n",
    "                    cv = 5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4b235a3f-2298-46e5-b1b0-b3195af7bb42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5,\n",
       "                   estimator=Pipeline(steps=[('tvec', TfidfVectorizer()),\n",
       "                                             ('nb', MultinomialNB())]),\n",
       "                   param_distributions={'nb__alpha': [0.01, 0.05, 0.1, 0.25,\n",
       "                                                      0.5, 0.1],\n",
       "                                        'tvec__max_features': range(600, 800, 5),\n",
       "                                        'tvec__ngram_range': [(1, 1), (1, 2),\n",
       "                                                              (1, 3), (2, 3),\n",
       "                                                              (3, 3)],\n",
       "                                        'tvec__stop_words': [['i', 'me', 'my',\n",
       "                                                              'myself', 'we',\n",
       "                                                              'our', 'ours',\n",
       "                                                              'ourselves',\n",
       "                                                              'you', \"you're\",\n",
       "                                                              \"you've\",\n",
       "                                                              \"you'll\", \"you'd\",\n",
       "                                                              'your', 'yours',\n",
       "                                                              'yourself',\n",
       "                                                              'yourselves',\n",
       "                                                              'he', 'him',\n",
       "                                                              'his', 'himself',\n",
       "                                                              'she', \"she's\",\n",
       "                                                              'her', 'hers',\n",
       "                                                              'herself', 'it',\n",
       "                                                              \"it's\", 'its',\n",
       "                                                              'itself', ...]]})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_rs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af41d613-3326-4c72-8172-d98a005dac34",
   "metadata": {},
   "source": [
    "# Model 2: LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e1d5db94-213f-41eb-999c-36db14169702",
   "metadata": {},
   "outputs": [],
   "source": [
    "logr_pipe = Pipeline([\n",
    "    ('tvec', TfidfVectorizer()),\n",
    "    ('logr', LogisticRegression())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b1ccbc67-fc00-4898-bfc6-7ab07bbe5c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "logr_pipe_params = {\n",
    "    'tvec__max_features': range(600,800,5),\n",
    "    'tvec__stop_words': [stop],\n",
    "    'tvec__ngram_range': [(1,1), (1,2), (1,3),(2,3),(3,3)],\n",
    "    'logr__C': [.01, .1 ,.5 , 1.0, 2, 5, 10]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "929fa21f-b79b-4973-8de4-8f5c685cfcb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "logr_rs = RandomizedSearchCV(logr_pipe, \n",
    "                  logr_pipe_params, \n",
    "                    cv = 5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8bae541a-4b14-4865-84db-4f7aa205955a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5,\n",
       "                   estimator=Pipeline(steps=[('tvec', TfidfVectorizer()),\n",
       "                                             ('logr', LogisticRegression())]),\n",
       "                   param_distributions={'logr__C': [0.01, 0.1, 0.5, 1.0, 2, 5,\n",
       "                                                    10],\n",
       "                                        'tvec__max_features': range(600, 800, 5),\n",
       "                                        'tvec__ngram_range': [(1, 1), (1, 2),\n",
       "                                                              (1, 3), (2, 3),\n",
       "                                                              (3, 3)],\n",
       "                                        'tvec__stop_words': [['i', 'me', 'my',\n",
       "                                                              'myself', 'we',\n",
       "                                                              'our', 'ours',\n",
       "                                                              'ourselves',\n",
       "                                                              'you', \"you're\",\n",
       "                                                              \"you've\",\n",
       "                                                              \"you'll\", \"you'd\",\n",
       "                                                              'your', 'yours',\n",
       "                                                              'yourself',\n",
       "                                                              'yourselves',\n",
       "                                                              'he', 'him',\n",
       "                                                              'his', 'himself',\n",
       "                                                              'she', \"she's\",\n",
       "                                                              'her', 'hers',\n",
       "                                                              'herself', 'it',\n",
       "                                                              \"it's\", 'its',\n",
       "                                                              'itself', ...]]})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logr_rs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "db1a1f46-a82f-4ad0-84ff-7993a734beff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9189564252012212\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8884263114071607"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(logr_rs.score(X_train, y_train))\n",
    "logr_rs.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22db6126-fdc8-48f8-9e05-bad62ec6d2a4",
   "metadata": {},
   "source": [
    "# Model 3: knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3d8162c1-6a80-4588-87a6-34dc2285831e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean = False here for memory error. see individual model for model with mean = True\n",
    "\n",
    "knn = Pipeline([\n",
    "    ('tvec', TfidfVectorizer()),\n",
    "    ('ss', StandardScaler(with_mean=False)),\n",
    "    ('knn', KNeighborsClassifier())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7322928a-e62e-418c-88f6-2d00061b6cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_params = {\n",
    "    'tvec__max_features': range(100,1000,100),\n",
    "    'tvec__stop_words': [stop],\n",
    "    'tvec__ngram_range': [(1,1), (1,2), (1,3),(2,3),(3,3)],\n",
    "    'knn__n_neighbors': range(1,20)\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cfe230c4-0f9a-41e9-b389-f9a3af5ac497",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=4,\n",
       "                   estimator=Pipeline(steps=[('tvec', TfidfVectorizer()),\n",
       "                                             ('ss',\n",
       "                                              StandardScaler(with_mean=False)),\n",
       "                                             ('knn', KNeighborsClassifier())]),\n",
       "                   param_distributions={'knn__n_neighbors': range(1, 20),\n",
       "                                        'tvec__max_features': range(100, 1000, 100),\n",
       "                                        'tvec__ngram_range': [(1, 1), (1, 2),\n",
       "                                                              (1, 3), (2, 3),\n",
       "                                                              (3, 3)],\n",
       "                                        'tvec__stop_words': [['i', 'me', 'my',\n",
       "                                                              'myself', 'we',\n",
       "                                                              'our', 'ours',\n",
       "                                                              'ourselves',\n",
       "                                                              'you', \"you're\",\n",
       "                                                              \"you've\",\n",
       "                                                              \"you'll\", \"you'd\",\n",
       "                                                              'your', 'yours',\n",
       "                                                              'yourself',\n",
       "                                                              'yourselves',\n",
       "                                                              'he', 'him',\n",
       "                                                              'his', 'himself',\n",
       "                                                              'she', \"she's\",\n",
       "                                                              'her', 'hers',\n",
       "                                                              'herself', 'it',\n",
       "                                                              \"it's\", 'its',\n",
       "                                                              'itself', ...]]})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_rs = RandomizedSearchCV(knn, knn_params, cv = 4)\n",
    "\n",
    "knn_rs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7ffd4cd1-59cb-469b-b69d-253b206118e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8726061615320566\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8459616985845129"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(knn_rs.score(X_train, y_train))\n",
    "knn_rs.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c31b05e-eb93-4819-a5a2-5f348f547c65",
   "metadata": {},
   "source": [
    "# Model 4: RF Boosted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c38e652d-02c4-44f0-97a2-fbc1600502ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "ada = Pipeline([\n",
    "    ('tvec', TfidfVectorizer()),\n",
    "    ('ada', AdaBoostClassifier(base_estimator = RandomForestClassifier()))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fcde5095-44ac-44a1-af9b-8c6e26bc18a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ada_params = {\n",
    "    'tvec__max_features': range(650,750,5),\n",
    "    'tvec__stop_words': [stop],\n",
    "    'tvec__ngram_range': [(1,1), (1,2), (1,3),(2,3),(3,3)],\n",
    "    'ada__n_estimators': range(100,200, 5)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fe374673-b392-4e52-829e-efdf1eaca6ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=4,\n",
       "                   estimator=Pipeline(steps=[('tvec', TfidfVectorizer()),\n",
       "                                             ('ada',\n",
       "                                              AdaBoostClassifier(base_estimator=RandomForestClassifier()))]),\n",
       "                   param_distributions={'ada__n_estimators': range(100, 200, 5),\n",
       "                                        'tvec__max_features': range(650, 750, 5),\n",
       "                                        'tvec__ngram_range': [(1, 1), (1, 2),\n",
       "                                                              (1, 3), (2, 3),\n",
       "                                                              (3, 3)],\n",
       "                                        'tvec__stop_words': [['i', 'me', 'my',\n",
       "                                                              'myself', 'we',\n",
       "                                                              'our', 'ours',\n",
       "                                                              'ourselves',\n",
       "                                                              'you', \"you're\",\n",
       "                                                              \"you've\",\n",
       "                                                              \"you'll\", \"you'd\",\n",
       "                                                              'your', 'yours',\n",
       "                                                              'yourself',\n",
       "                                                              'yourselves',\n",
       "                                                              'he', 'him',\n",
       "                                                              'his', 'himself',\n",
       "                                                              'she', \"she's\",\n",
       "                                                              'her', 'hers',\n",
       "                                                              'herself', 'it',\n",
       "                                                              \"it's\", 'its',\n",
       "                                                              'itself', ...]]})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ada_rf_rs = RandomizedSearchCV(ada, ada_params, cv = 4)\n",
    "\n",
    "ada_rf_rs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e6b81bd7-485f-4763-b806-75d37201c8dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9994449070219261\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8476269775187344"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(ada_rf_rs.score(X_train, y_train))\n",
    "ada_rf_rs.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8996119-a588-4a72-a55b-eb5da02b9a41",
   "metadata": {},
   "source": [
    "# Model 5: Gradient boosting DT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0f6e55ee-34a8-43cb-800f-6804f51c779c",
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_pipe = Pipeline([\n",
    "    ('tvec', TfidfVectorizer()),\n",
    "    ('gb', GradientBoostingClassifier())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b85645a1-b181-4171-80d3-daddb9ba162e",
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_pipe_params = {\n",
    "    'tvec__max_features': range(600,800,5),\n",
    "    'tvec__stop_words': [stop],\n",
    "    'tvec__ngram_range': [(1,1), (1,2), (1,3),(2,3),(3,3)],\n",
    "    'gb__n_estimators': range(50,200,50),\n",
    "    'gb__max_features': range(50, 80)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "339c9e4f-189e-464b-b037-424f99ad0aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_rs = RandomizedSearchCV(gb_pipe, \n",
    "                  gb_pipe_params, \n",
    "                    cv = 5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "253ec55f-ac0d-4fed-a775-9437dcc70629",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5,\n",
       "                   estimator=Pipeline(steps=[('tvec', TfidfVectorizer()),\n",
       "                                             ('gb',\n",
       "                                              GradientBoostingClassifier())]),\n",
       "                   param_distributions={'gb__max_features': range(50, 80),\n",
       "                                        'gb__n_estimators': range(50, 200, 50),\n",
       "                                        'tvec__max_features': range(600, 800, 5),\n",
       "                                        'tvec__ngram_range': [(1, 1), (1, 2),\n",
       "                                                              (1, 3), (2, 3),\n",
       "                                                              (3, 3)],\n",
       "                                        'tvec__stop_words': [['i', 'me', 'my',\n",
       "                                                              'myself', 'we',\n",
       "                                                              'our', 'ours',\n",
       "                                                              'ourselves',\n",
       "                                                              'you', \"you're\",\n",
       "                                                              \"you've\",\n",
       "                                                              \"you'll\", \"you'd\",\n",
       "                                                              'your', 'yours',\n",
       "                                                              'yourself',\n",
       "                                                              'yourselves',\n",
       "                                                              'he', 'him',\n",
       "                                                              'his', 'himself',\n",
       "                                                              'she', \"she's\",\n",
       "                                                              'her', 'hers',\n",
       "                                                              'herself', 'it',\n",
       "                                                              \"it's\", 'its',\n",
       "                                                              'itself', ...]]})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb_rs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1a1db125-2c8f-4832-b463-ad09efbc42e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9117402164862615\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.880932556203164"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(gb_rs.score(X_train, y_train))\n",
    "gb_rs.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "530d341d-e8b6-4c63-a7d4-c13fb34b7506",
   "metadata": {},
   "source": [
    "# Model 6: Stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6fb9a8c-6100-4860-824e-04f2748bc944",
   "metadata": {},
   "outputs": [],
   "source": [
    "stack_estimators = [\n",
    "    ('nb_pipe', nb_rs.best_estimator_),\n",
    "    ('ada_pipe', ada_rf_rs.best_estimator_),\n",
    "    ('gb_pipe', gb_rs.best_estimator_),\n",
    "    ('logr_pipe', logr_rs.best_estimator_)   \n",
    "]\n",
    "\n",
    "stack = StackingClassifier(estimators=stack_estimators, final_estimator=LogisticRegression())\n",
    "\n",
    "cross_val_score(stack, X_train, y_train).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef909fb9-9da4-4587-9510-df51bffbd16e",
   "metadata": {},
   "outputs": [],
   "source": [
    "stack.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "809a5d58-df45-4aca-afe2-693f3ae692ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(stack.score(X_train, y_train))\n",
    "stack.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92c4e595-a0f7-448a-b9bf-32f064859a8c",
   "metadata": {},
   "source": [
    "# Make list of models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f0b4453-8543-4e3e-bdf8-8859c959ad55",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [nb_rs, logr_rs, knn_rs, ada_rf_rs, gb_rs, stack]\n",
    "modelsstr =  ['nb_rs', 'logr_rs', 'knn_rs', 'ada_rf_rs', 'gb_rs', 'stack']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc90519c-4aee-42e1-8801-693d5587015b",
   "metadata": {},
   "source": [
    "# Generate predictions for models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945dc49b-fad5-4bbe-82cc-b4682a47d6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preds_gen(estimator):\n",
    "    return estimator.predict(X_test)\n",
    "\n",
    "preds_array = []\n",
    "\n",
    "for i in models:\n",
    "    preds_array.append(preds_gen(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb5cdfb7-2e92-4737-9d89-e95376019568",
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrices(model, preds):\n",
    "    \n",
    "    cm = confusion_matrix(y_test, preds)\n",
    "\n",
    "    display = ConfusionMatrixDisplay(confusion_matrix = cm,\n",
    "                                 display_labels = model.classes_)\n",
    "    display.plot();\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4c1613f-0083-4c09-9a3a-f0806aa1fd71",
   "metadata": {},
   "source": [
    "# Generate confusion matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e047e39c-91b7-4a34-b434-b3f1be80662a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in preds_array:\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, i).ravel()\n",
    "    print(tn, fp, fn, tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5116b38-346e-4676-8969-820db5cfe780",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = []\n",
    "for i in preds_array:\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, i).ravel()\n",
    "    \n",
    "    d.append(\n",
    "        {\n",
    "            'tn': tn,\n",
    "            'fp': fp,\n",
    "            'fn': fn,\n",
    "            'tp': tp\n",
    "        }\n",
    "    )\n",
    "\n",
    "cf_df = pd.DataFrame(d)\n",
    "cf_df['model'] = pd.Series(modelsstr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fffab92-145d-4d92-8d58-4d2174f88c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_df['sensitivity'] = (cf_df['tp'] / (cf_df['tp'] + cf_df['fn']))*100\n",
    "cf_df['specificity'] = (cf_df['tn'] / (cf_df['tn'] + cf_df['fp']))*100\n",
    "cf_df['precision'] = (cf_df['tp'] / (cf_df['tp'] + cf_df['fp']))*100\n",
    "cf_df['neg_predicitve_val'] = (cf_df['tn'] / (cf_df['tn'] + cf_df['fn']))*100\n",
    "cf_df['accuracy'] = ((cf_df['tp'] + cf_df['tn']) / (cf_df['tp'] + cf_df['tn'] + cf_df['fp'] + cf_df['fn']))*100\n",
    "cf_df['f1'] = (2*cf_df['tp'] /  (2*cf_df['tp'] + cf_df['fp'] + cf_df['fn']))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25715e13-d972-4b8d-856b-682cf97c9e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_df['test_score'] = [i.score(X_test, y_test) for i in models]\n",
    "cf_df['fit'] = [((i.score(X_test, y_test) - i.score(X_train, y_train))/i.score(X_test, y_test))*100 for i in models]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1bb2ec-f4d8-43c0-95de-985f42149659",
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c11a57e-62d5-43ec-8cca-5113345848cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [i for i in cf_df.columns if i not in ['tn', 'tp', 'fn', 'fp', 'model']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce4e19c2-8cb3-49c3-a3ff-31873b4f043f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_df[cols] = cf_df[cols].apply(lambda x: pd.Series.round(x, 2))\n",
    "cf_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c4fc066-8e1f-4a9c-8e26-9f2c9d3dd5bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_df[['model', 'sensitivity', 'fit', 'accuracy']].sort_values(by = 'accuracy', ascending = False).plot(x='model', kind='bar')\n",
    "plt.title('key model performance metrics')\n",
    "plt.tight_layout();\n",
    "plt.savefig('../images/modelperf.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13876ab4-4d9d-4187-8dcf-3dfd63e1b99b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_df[['model', 'f1', 'fp', 'fn']].sort_values(by = 'f1', ascending = False).plot(x='model', kind='bar')\n",
    "plt.title('model F1 and misclassification')\n",
    "plt.tight_layout();\n",
    "plt.savefig('../images/misclassification.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a917e594-dbe0-43eb-a962-1e0109f5e3ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_df.set_index('model').sort_values(by = 'f1', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e23ec5ce-1822-4933-ace2-f2e1af662b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for i,z in zip(models, preds_array):\n",
    "    \n",
    "    title = modelsstr[count]\n",
    "    \n",
    "    cm = confusion_matrix(y_test, z)\n",
    "    \n",
    "    disp = ConfusionMatrixDisplay.from_estimator(\n",
    "        i,\n",
    "        X_test,\n",
    "        y_test,\n",
    "        display_labels=i.classes_,\n",
    "        cmap=plt.cm.Blues,\n",
    "    )\n",
    "    disp.ax_.set_title(title)\n",
    "    count+=1\n",
    "    print(disp.confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647182b8-23da-4aa4-aa62-bd1a315c73a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save for pres\n",
    "\n",
    "cm = confusion_matrix(y_test, preds_array[-1])\n",
    "\n",
    "disp = ConfusionMatrixDisplay.from_estimator(\n",
    "    stack,\n",
    "    X_test,\n",
    "    y_test,\n",
    "    display_labels=stack.classes_,\n",
    "    cmap=plt.cm.Blues,\n",
    ")\n",
    "disp.ax_.set_title(title)\n",
    "plt.savefig('../images/stack_confusion')\n",
    "print(disp.confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e46bbc6-3b87-490a-9ba6-93c1f06fd477",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1476f604-5002-436a-9788-c16f63ec8629",
   "metadata": {},
   "source": [
    "# Plot some ROCs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db38f421-98d5-4432-a208-7457927de00f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# notes\n",
    "def ROC(model, name):\n",
    "\n",
    "    ax = plt.gca()\n",
    "\n",
    "    # use RocCurveDisplay for both estimators\n",
    "    RocCurveDisplay.from_estimator(model, X_test, y_test, ax=ax, name=name)\n",
    "\n",
    "    # add 'worst case scenario' line\n",
    "    #plt.plot([0,1], [0,1], label='null hypothesis/mean', linestyle='--', color='gray')\n",
    "\n",
    "    # necessary to label the baseline\n",
    "    plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d9a9ce-b876-4a20-82d1-f4e49e833bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in zip(models, modelsstr):\n",
    "    print(ROC(*i))\n",
    "    #plt.show();\n",
    "    #plt.savefig('../images/ROC')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "761e53ee-effa-4e32-baf6-60ae7a489058",
   "metadata": {},
   "source": [
    "# Preds analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa75e9e2-b7fd-479e-8f9c-1cdac0fe35fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_dfs(model):\n",
    "\n",
    "    pred_df = pd.DataFrame(model.predict_proba(X_test),columns=['bitcoin', 'ethereum'])\n",
    "\n",
    "    pred_df['true_values'] = y_test.values\n",
    "\n",
    "    return pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1debba0b-8143-464b-8925-2c0ce09fb0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_preds, logr_preds, knn_preds, ada_preds, gb_preds, stack_preds = [pred_dfs(i) for i in models]\n",
    "\n",
    "pred_arrays = [nb_preds, logr_preds, knn_preds, ada_preds, gb_preds, stack_preds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fcb543c-aa26-447d-8b1d-a86e16a58563",
   "metadata": {},
   "outputs": [],
   "source": [
    "#notes\n",
    "def class_from_prob(probabilities, threshold):\n",
    "\n",
    "    return [0 if prob < threshold else 1 for prob in probabilities]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee2e4c0d-6228-4cfa-9a49-d02b4d8142bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_tables(models, modelsstr):\n",
    "    counter = 0\n",
    "    for i in pred_arrays:\n",
    "        \n",
    "        threshold_list = [round(i*.01,2) for i in range(0,101,)]\n",
    "        speclist = []\n",
    "        senslist = []\n",
    "        f1list = []\n",
    "\n",
    "        for threshold in threshold_list:\n",
    "            predicted_classes = class_from_prob(i['ethereum'], threshold)\n",
    "            spec = specificity_score(y_test, predicted_classes)\n",
    "            sens = recall_score(y_test, predicted_classes, pos_label=1)\n",
    "            speclist.append(spec)\n",
    "            senslist.append(sens)\n",
    "            F1 = f1_score(y_test, predicted_classes)\n",
    "            f1list.append(F1)\n",
    "        \n",
    "        \n",
    "        %matplotlib inline\n",
    "        fig = plt.figure(figsize = (10,5));\n",
    "        ax1 = fig.add_subplot(111);\n",
    "\n",
    "        ax1.scatter(x = threshold_list, y = speclist, s=10, c='b', marker=\"s\", label='specificity');\n",
    "        ax1.scatter(x = threshold_list,y = senslist, s=10, c='r', marker=\"o\", label='sensitivity');\n",
    "        ax1.scatter(x = threshold_list,y = f1list, s=10, c='g', marker=\"o\", label='F1 score');\n",
    "        plt.legend(loc='upper left')\n",
    "        plt.xlabel('Threshold');\n",
    "        plt.ylabel('Score Value');\n",
    "        plt.title(f'{modelsstr[counter]}')\n",
    "        counter +=1 \n",
    "        plt.show();\n",
    "        plt.tight_layout();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02258cc9-b09e-4a89-a2d6-94a8964a361d",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_tables(models, modelsstr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a257c8d-43c9-4857-b550-2e7f160375c7",
   "metadata": {},
   "source": [
    "# More details (Stack estimator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f8d17ab-6c5c-4a12-8ad6-3699cced8f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = pd.DataFrame(stack.predict_proba(X_test),columns=['bitcoin', 'ethereum'])\n",
    "\n",
    "pred_df['true_values'] = y_test.values\n",
    "\n",
    "pred_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e49382d5-4ef0-47b2-abb0-f206fe9b03fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_selftext = df_selftext.join(pred_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a418c4-78ef-4d19-911b-3a37d8c42930",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_selftext.sort_values(by = 'bitcoin')[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5de2753-4d9a-41c3-9729-5423c0133de2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66617957-415d-4261-a79a-306b1b558c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_list = [round(i*.01,2) for i in range(0,101,)]\n",
    "speclist = []\n",
    "senslist = []\n",
    "f1list = []\n",
    "\n",
    "for threshold in threshold_list:\n",
    "    predicted_classes = class_from_prob(pred_df['ethereum'], threshold)\n",
    "    spec = specificity_score(y_test, predicted_classes)\n",
    "    sens = recall_score(y_test, predicted_classes, pos_label=1)\n",
    "    speclist.append(spec)\n",
    "    senslist.append(sens)\n",
    "    F1 = f1_score(y_test, predicted_classes)\n",
    "    f1list.append(F1)\n",
    "    \n",
    "    \n",
    "%matplotlib inline\n",
    "fig = plt.figure(figsize = (10,5));\n",
    "ax1 = fig.add_subplot(111);\n",
    "\n",
    "ax1.scatter(x = threshold_list, y = speclist, s=10, c='b', marker=\"s\", label='specificity');\n",
    "ax1.scatter(x = threshold_list,y = senslist, s=10, c='r', marker=\"o\", label='sensitivity');\n",
    "ax1.scatter(x = threshold_list,y = f1list, s=10, c='g', marker=\"o\", label='F1 score');\n",
    "plt.legend(loc='upper left')\n",
    "plt.xlabel('Threshold');\n",
    "plt.ylabel('Score Value');\n",
    "plt.tight_layout();\n",
    "plt.savefig('../images/threshold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497393ed-be53-4f5d-b6a9-ae737aa73fb8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2d1ede-eaf7-4039-820b-529eeffddfb3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4889bd8d-f32a-43e1-a224-9ea2a5eb6e9a",
   "metadata": {},
   "source": [
    "# False negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd61e39-5369-495f-9082-219e0ea16e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_selftext[(df_selftext.true_values == 1) & (df_selftext.bitcoin > .5)].sort_values(by = 'bitcoin', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b184fa86-3fb5-4c99-bc4a-2ee692bccd80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment for df\n",
    "for i in df_selftext[(df_selftext.true_values == 1) & (df_selftext.bitcoin > .5)]['text']:\n",
    "    print(i, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d1f9f5-cde4-4ecf-bba1-b0ba12b97760",
   "metadata": {},
   "source": [
    "# False Positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff65f21-f104-41ec-aebd-64588a6a0951",
   "metadata": {},
   "outputs": [],
   "source": [
    "FP = pred_df.loc[(pred_df['ethereum'] > .5) & (pred_df.true_values == 0)].index.values.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fede62f-836a-4f79-bd5c-a1252e6ab56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in df_selftext.iloc[FP].text:\n",
    "    print(i,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f603410e-fbc6-4ae2-9916-afc211cef031",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b9bc072-d12b-4d87-afbf-f1a8cd8455f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df7be04-5ecf-4351-8b83-e8c5b7a80358",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d23357-c174-4d2b-a900-0425c59e5280",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c7b0479-b3ca-421d-90e5-e31481141a46",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b46aa0b-1db9-46e5-935d-6b481569777e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from praw.models import MoreComments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "523ac845-bf84-4cde-aebf-3721c4274037",
   "metadata": {},
   "outputs": [],
   "source": [
    "import praw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a8ffe38-f14d-4d1e-a628-7fa479eaf654",
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit = praw.Reddit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c981f348-7e12-42fc-80d7-20ed70b96b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit.read_only = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb08e5c-ee93-401d-9076-a55146eaae55",
   "metadata": {},
   "source": [
    "# API call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "599fcd22-b39c-4a5a-b406-d09f065da4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ethereum = reddit.subreddit(\"ethereum\")\n",
    "bitcoin = reddit.subreddit('bitcoin')\n",
    "\n",
    "subreddits = [bitcoin, ethereum]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2055efdf-ae3e-4a55-a769-1e81e16d6388",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://praw.readthedocs.io/en/stable/code_overview/models/submission.html\n",
    "\n",
    "#https://www.reddit.com/r/redditdev/comments/rsz7za/getting_submissions_from_praw_extremely_slow/\n",
    "\n",
    "'''The slowdown is mostly due to PRAW. In the loop in line 42 you are reading a bunch of attributes of each \n",
    "submission (id, title, ...). Most of them are read when you get the subreddit feeds, but not all of them. \n",
    "The missing ones seem to be **author.name** and **upvote_ratio**. If you are trying to call those attributes, a new \n",
    "network request has to be made, which takes around half a secong for each post. Check this part of the documentation \n",
    "for a better explanation.'''\n",
    "\n",
    "\n",
    "        \n",
    "'''replace_more, and just generally, digging deep into a Reddit comment tree, is a \n",
    "           slow operation and will consume your rate limit (thus the slowdown you see).'''\n",
    "        \n",
    "'''When you access the .upvote_ratio attribute it makes a request to fetch \"all\" the comments for that post. \n",
    "\n",
    "If so that would mean you need to make another request for each post - which would be another 100 http requests - \n",
    "perhaps this is where the slow down is happening? This would mean 300 http requests for new, hot, and rising \n",
    "combined per subreddit just for this upvote_ratio'''\n",
    "\n",
    "\n",
    "def call(i):\n",
    "    # pass an object from subreddits\n",
    "\n",
    "    \n",
    "        #API params\n",
    "        limitval = 10\n",
    "        sorting = {'top': i.top(limit = limitval), 'new': i.new(limit = limitval), 'hot': i.hot(limit = limitval)}\n",
    "        APIsorter = sorting['top']\n",
    "        \n",
    "\n",
    "        post_titles = []\n",
    "        post_upvoteses = []\n",
    "        num_commentses = []\n",
    "        # Annoying names for semantic formulism to resolve identity errors (eg num_comments.append(num_comments). There are no other LOTR jokes in this doc. \n",
    "        post_ids = []\n",
    "        #slowdown\n",
    "        post_upvote_ratios = []\n",
    "        post_comments = []\n",
    "        post_upvotes = []\n",
    "        post_dates = []\n",
    "        post_scores = []\n",
    "        post_texts = []\n",
    "        post_authors = []\n",
    "        #slowdown\n",
    "        comment_authors = []\n",
    "        comment_bodies = []\n",
    "        comment_submissions = []\n",
    "        comment_upvotes = []\n",
    "        \n",
    "\n",
    "        \n",
    "        for submission in APIsorter:\n",
    "            post_title = submission.title\n",
    "            post_upvotes = submission.score\n",
    "            num_comments = submission.num_comments\n",
    "            post_id = submission.id\n",
    "            upvote_ratio = submission.upvote_ratio\n",
    "            post_comment_list = list(submission.comments)\n",
    "            post_date = submission.created_utc\n",
    "            post_score = submission.score\n",
    "            post_text = submission.selftext\n",
    "            post_author = submission.author\n",
    "\n",
    "            post_titles.append(post_title)\n",
    "            post_upvoteses.append(post_upvotes)\n",
    "            num_commentses.append(num_comments)\n",
    "            post_ids.append(post_id)\n",
    "            post_upvote_ratios.append(upvote_ratio)\n",
    "            post_comments.append(post_comment_list)\n",
    "            post_dates.append(post_date)\n",
    "            post_scores.append(post_score)\n",
    "            post_texts.append(post_text)\n",
    "            post_authors.append(post_author)\n",
    "            \n",
    "\n",
    "    #https://praw.readthedocs.io/en/v7.3.0/tutorials/comments.html\n",
    "\n",
    "            submission.comments.replace_more(limit = None)\n",
    "\n",
    "            for comment in submission.comments.list():\n",
    "                    comment_author = comment.author\n",
    "                    comment_body = comment.body\n",
    "                    comment_submission = comment.submission\n",
    "                    comment_upvote = comment.score\n",
    "                    comment_authors.append(comment_author)\n",
    "                    comment_bodies.append(comment_body)\n",
    "                    comment_submissions.append(comment_submission)\n",
    "                    comment_upvotes.append(comment_upvote)\n",
    "\n",
    "\n",
    "        #stick in DF, could be new method but put it in here\n",
    "\n",
    "        df_posts = pd.DataFrame({\n",
    "        'title': post_titles,\n",
    "        'post_num_comments': num_commentses,\n",
    "        'post_upvotes': post_upvoteses,\n",
    "        'post_id': post_ids,\n",
    "        'post_upvote_ratios':post_upvote_ratios,\n",
    "        'post_datetime':post_dates,\n",
    "        'post_score': post_scores,\n",
    "        'post_text': post_texts,\n",
    "        'post_upvote_ratio': post_upvote_ratios,\n",
    "        'post_author':post_authors\n",
    "\n",
    "        })\n",
    "\n",
    "        \n",
    "        print(df_posts)\n",
    "\n",
    "        df_comments = pd.DataFrame({\n",
    "        'comment_author': comment_authors,\n",
    "        'comment_body': comment_bodies,\n",
    "        'comment_submission': comment_submissions,\n",
    "        'comment_upvotes': comment_upvotes\n",
    "\n",
    "\n",
    "        })\n",
    "    \n",
    "        return df_posts, df_comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4b3fcad8-3c01-48ae-83f0-18fd722b8ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# want to make variable variables here. Seems unpopular however"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b55cf534-30ba-4fbf-a1db-36ae622e3703",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a4b6fe-9c0a-41c8-ba07-f3191d1411ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               title  post_num_comments  \\\n",
      "0  Vitalik Buterin: Cryptocurrency Should Focus L...                896   \n",
      "1  Yesterday I received my very first payment for...               1318   \n",
      "2                                              Nft ðŸ˜‘               2070   \n",
      "3  Reddit announces partnership with the Ethereum...                893   \n",
      "4  Bitcoin Miami Conference warns attendees it's ...                806   \n",
      "5  The Ethereum blockchain now processes about as...                537   \n",
      "6  I see everyone getting exited over burning ETH...                442   \n",
      "7                                  Mark mic dropping                917   \n",
      "8  Goldman Sachs calls Ethereum \"The Amazon Of In...                504   \n",
      "9  Why is this address sending thousands of 0 ETH...                460   \n",
      "\n",
      "   post_upvotes post_id  post_upvote_ratios  post_datetime  post_score  \\\n",
      "0          7732  7mve4y                0.91   1.514566e+09        7733   \n",
      "1          7497  nwcnzg                0.93   1.623292e+09        7494   \n",
      "2          7441  qxxyet                0.93   1.637383e+09        7445   \n",
      "3          7223  l6c3kx                0.96   1.611775e+09        7227   \n",
      "4          7055  nswuyf                0.92   1.622903e+09        7046   \n",
      "5          6379  7qckfb                0.92   1.515945e+09        6374   \n",
      "6          6272  o7sx7x                0.96   1.624644e+09        6271   \n",
      "7          6271  nrfu99                0.90   1.622733e+09        6260   \n",
      "8          5936  njdhxn                0.95   1.621794e+09        5932   \n",
      "9          5903  rtpd1h                0.97   1.641062e+09        5897   \n",
      "\n",
      "                                           post_text  post_upvote_ratio  \\\n",
      "0                                                                  0.91   \n",
      "1                                                                  0.93   \n",
      "2                                                                  0.93   \n",
      "3  Hello, Ethereum world!\\n\\nReddit admin [u/jari...               0.96   \n",
      "4                                                                  0.92   \n",
      "5                                                                  0.92   \n",
      "6                                                                  0.96   \n",
      "7                                                                  0.90   \n",
      "8                                                                  0.95   \n",
      "9  What's up with this address?  They're spending...               0.97   \n",
      "\n",
      "        post_author  \n",
      "0     thedesertlynx  \n",
      "1    BigDaddyDallas  \n",
      "2       Clutchbotv3  \n",
      "3            jarins  \n",
      "4      Theory-Early  \n",
      "5  antiprosynthesis  \n",
      "6      terp_studios  \n",
      "7             Flawe  \n",
      "8           twigwam  \n",
      "9              None  \n"
     ]
    }
   ],
   "source": [
    "df_posts_ethereum, df_comments_ethereum = call(subreddits[1])\n",
    "\n",
    "df_posts_bitcoin, df_comments_bitcoin = call(subreddits[0])\n",
    "            \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54fee719-8832-4305-80fa-0e901c280018",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_posts_ethereum.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866451fb-4ecf-4aec-82d4-23a43e718d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_posts_bitcoin.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9129c9eb-c75b-4a46-a29f-7313bdaa3e32",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44caef11-7358-4296-8891-539722fc6204",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get users\n",
    "#https://stackoverflow.com/questions/32314937/how-do-i-use-praw-and-python-to-retrieve-reddit-post-data-from-a-certain-user\n",
    "#https://www.reddit.com/r/redditdev/comments/gtmnaq/grabbing_all_postscomments_from_a_specific_user/\n",
    "\n",
    "'''\n",
    "Instead of using reddit.redditor(\"username\") you can also use reddit.subreddit(\"r/u_username\") \n",
    "so, if you want to stream your posts and comments then you can use r/u_superior__peach\n",
    "If you include r/u_ before any username, you can use reddit.subreddit(\"r/u_superior__peach\")\n",
    "The main advantage of using the above mentioned method is that you can use all of the attributes \n",
    "and methods that are defined in reddit.subreddit() class.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ece595-a9a6-42b6-b92b-b6327947f920",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_submissions = user.get_submitted()\n",
    "\n",
    "user_submissions = []\n",
    "for link in submissions:\n",
    "    self_texts.append(link.selftext)\n",
    "\n",
    "print self_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac96c8e2-8e73-4242-9384-3881c99421a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e1e7325-1a69-4989-acbd-cd8148e30c10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf846ed-b3c3-4050-b1cf-d1f22a2f3c88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "686b3c22-25a0-4b05-92bb-ac47810191fd",
   "metadata": {},
   "source": [
    "# Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bee128f-a77e-4a80-9065-ba3d071e169e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def format_date(df):\n",
    "    df['post_datetime'] = pd.to_datetime(df['post_datetime'], unit = 's')\n",
    "    df['post_date'] = df['post_datetime'].dt.date\n",
    "    df['post_time'] = df['post_datetime'].dt.time\n",
    "    df.drop(['post_datetime'], axis = 1, inplace = True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc99ce8f-6b4a-4f3a-93ef-6866aad14025",
   "metadata": {},
   "outputs": [],
   "source": [
    "[format_date(i) for i in [df_posts_bitcoin, df_posts_ethereum]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d643ba91-db83-40d8-b063-d1a818d2e16b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_posts_ethereum.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3665507c-843f-434d-9c6b-b8a4eb4a5e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comments_bitcoin.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1200cd0b-fe91-4dc2-8d5b-e165ef07294c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comments_ethereum.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b99520ad-79fe-43bd-b021-8ef0d7effdb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_joined = df_post.merge(df_comments, left_on='post_id', right_on='comment_submission', how='right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5dbfba5-4d57-40ae-b0ed-abfa2cbc4f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. join posts with posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca1ce1c-f6f2-48b9-8098-97511d4bcd85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c1b6f28-5778-4b71-aa2c-7bf847fc28fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74534313-829c-4ff3-94c5-c07b5b68d8cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc9b78a-fe57-40b5-a4c5-105be0728561",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 join comments w/comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "485f5edf-0ce9-4acc-aeb7-334627c50166",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983bb13f-9444-4c42-9113-744f68374aa8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0475c9e8-d480-4a59-b92d-ddc9b69eff66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f66caca9-7c94-4679-b6ec-b027e921b5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. join comments w/posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20918329-cbe2-46f8-9602-55d02803e88a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b21e88-6254-44bb-a1e6-c0e39bcf6444",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fb20be33-55d2-445b-b925-e6354dd38a16",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc279cb-cffe-44bc-b624-276daa020fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Questions\n",
    "\n",
    "1. How many are text vs. content?\n",
    "2. Authorship\n",
    "3. Title keywords\n",
    "4. Text keywords\n",
    "5. Title / text relationship\n",
    "6. Price / timeseries\n",
    "7. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "959c977a-5130-49e1-bd14-21e7d3f9d87b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e8654c49-d9b4-44d3-8a38-de11f6097bae",
   "metadata": {},
   "source": [
    "# Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7309488a-c95f-455b-8690-9b1be4324c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_post.to_csv('./data/source.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80df0cc6-7d00-44bb-aef7-ff54dace7c70",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
